var documenterSearchIndex = {"docs":
[{"location":"#A-Toolbox-for-Solving-Dynamic-Rational-Inattention-Problems-1","page":"Home","title":"A Toolbox for Solving Dynamic Rational Inattention Problems","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"This notebook explains how to solve LQG Dynamic Rational Inattention models using the methods and the solver from Afrouzi and Yang (2019) that was adapted for Julia by the authors and Miguel Acosta. ","category":"page"},{"location":"#","page":"Home","title":"Home","text":"To add the package, execute:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"] DRIPs","category":"page"},{"location":"#","page":"Home","title":"Home","text":"To include the package, execute:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"using DRIP;","category":"page"},{"location":"#A-Structure-for-LQG-Dynamic-Rational-Inattention-Problems-(D.R.I.P.)-1","page":"Home","title":"A Structure for LQG Dynamic Rational Inattention Problems (D.R.I.P.)","text":"","category":"section"},{"location":"#The-Problem-1","page":"Home","title":"The Problem","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"A LQG Dynamic Rational Inattention Problem (drip) is defined as the following tracking problem, where at any point in time the agent chooses a vector of actions veca_tinmathbbR^m to track a Gaussian stochastic process vecx_tinmathbbR^n: \\begin{align}     & \\min{{\\vec{a}t}{t\\geq 0}} \\mathbb{E}\\left[\\sum{t=0}^\\infty \\beta^t (\\vec{a}t - \\vec{x}t'\\mathbf{H})'(\\vec{a}t - \\vec{x}t'\\mathbf{H}) - \\omega \\mathbb{I}(\\vec{a}^t;\\vec{x}^t|\\vec{a}^{t-1})\\lvert \\vec{a}^{-1}\\right] \\\n    s.t.\\quad &         \\vec{x}t=\\mathbf{A}\\vec{x}{t-1}+\\mathbf{Q}\\vec{u}t,\\quad \\vec{u}t\\sim \\mathcal{N}(\\mathbf{0},\\mathbf{I}^{k\\times k}) \\end{align} Here:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"veca_tinmathbbR^m\nis the vector of the agent's actions at time t (a firms choosing a price, or a househld choosing consumption and labor etc.) We denote the number of actions by m.\nvecx_tinmathbbR^n\nis the vector of the shocks that the agent faces at time t that are exogenous to her decision, but could be endogenous to the GE model (marginal cost of a firm, real interest rates etc.) We denote the number of shocks by n.","category":"page"},{"location":"#The-Parameters-1","page":"Home","title":"The Parameters","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"The LQG-DRI problem is characterized by the following parameters:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"omegain mathbbR_+\n: cost of 1 bit of information in units of the agent's payoff. \nbetain01\n: rate of discounting information.\nmathbfAin mathbbR^ntimes n mathbfQinmathbbR^ntimes k\n: Determine the state space representation of vecx_t.\nmathbfHin mathbbR^ntimes m\n: interaction of payoffs with shocks. This comes from a second order approximation to the utility function and is such that under full information veca^*=mathbfHvecx.","category":"page"},{"location":"#The-Solution-1","page":"Home","title":"The Solution","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"The solution to the dynamic rational inattention problem is a joint stochastic process between the actions and the states: (veca_tvecx_t)tgeq 0. Moreover, in some economic applications, we are also interested in the law of motion for the agent's belief about vecx_t under the optimal information structure hatx_t=mathbbE_tvecx_t where the expectation is taken conditional on the agent's time t information.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Theorem 2 and Proposition 3 in Afrouzi and Yang (2019) characterize this joint distribution as a function of a tuple (mathbfKmathbfYmathbfSigma_z) where \\begin{align}     \\vec{a}t &= \\mathbf{H}'\\hat{x}t = \\mathbf{H}'\\mathbf{A}\\hat{x}{t-1}+\\mathbf{Y}'(\\vec{x}t-\\mathbf{A}\\hat{x}{t-1})+\\vec{z}t \\\n    \\hat{x}t &= \\mathbf{A}\\hat{x}{t-1}+\\mathbf{K}\\mathbf{Y}'(\\vec{x}t-\\mathbf{A}\\hat{x}{t-1})+\\mathbf{K}\\vec{z}t,\\quad \\vec{z}\\sim\\mathcal{N}(0,\\Sigmaz) \\end{align}","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Here, ","category":"page"},{"location":"#","page":"Home","title":"Home","text":"mathbfKinmathbbR^ntimes m\nis the Kalman-gain matrix of the agent in under optimal information acquisition in the stationary solution.\nmathbfYinmathbbR^mtimes m\nmaps the state to the agent's action under rational inattetion and govern the covariance of the two.\nmathbfSigma_zinmathbbR^mtimes m\nis the variance-covariance matrix of the agent's rational inattention error.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"In addition to these, we might also be interested in the agent's prior and posterior subjective undertainty, along with the continution value that she assigns to information:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"mathbfSigma_p=mathbbVar(vecx_tveca^t)inmathbbR^ntimes n\n.\nmathbfSigma_-1=mathbbVar(vecx_tveca^t-1)inmathbbR^ntimes n\n, \nbarOmegainmathbbR^ntimes n\n.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"The matrix barOmega, which is the continuation value of information, is also important for the number of iterations that the code needs to converge. When n is large, accurate guesses for barOmega and mathbfSigma_-1 speed up the convergence considerably.","category":"page"},{"location":"#The-Solver-for-the-Steady-State-of-D.R.I.P.-1","page":"Home","title":"The Solver for the Steady State of D.R.I.P.","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"The solver function is solve_drip(ω,β,A,Q,H;Σ0 = A*A'+Q*Q',Ω0 = H*H'). It takes the primitives (ω,β,A,Q,H;Σ0,Ω0) as arguments, where the arguments Σ0,Ω0 are the initial guesses for mathbfSigma_-1 and barOmega and are optional for cases in which an accurate initial guess is at hand. If not specified, the default values are set as Ω0=H*H' and Σ0=Q*Q'. See the code for extra options regarding tolerance of convergence, maximum number of iterations, and updating weight for every iteration.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"The function returns the solution of the model within a drip structure,  that contains all the primitives and the solution objects of the model:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"mutable struct Drip \n    ω; β; A; Q; H;                    # primitives\n    K; Y; Σ_z; Σ_p; Σ_1; Ω;           # solution\n    Drip()          = new();\n    Drip(ω,β,A,Q,H) = new(ω,β,A,Q,H);\nend","category":"page"},{"location":"#Impulse-Resonse-Functions-using-Steady-State-Information-Structure-1","page":"Home","title":"Impulse Resonse Functions using Steady State Information Structure","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Once the model is solved, one can generate the impulse response functions of actions and beliefs using the laws of motion stated above. ","category":"page"},{"location":"#","page":"Home","title":"Home","text":"We have also included a built-in function that generates these IRFs. The function dripirfs(P::drip,T::Int) takes a drip structure as input along with the length of irfs T and returns the irfs of the state, beliefs and actions to all possible shocks in the following structure:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"struct Dripirfs\n    T     :: Int            # length of IRFs\n    x     :: Array{Float64} # IRFs of the fundamental shocks\n    x_hat :: Array{Float64} # IRFs of beliefs\n    a     :: Array{Float64} # IRFs of actions\nend","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Here ","category":"page"},{"location":"#","page":"Home","title":"Home","text":"x is of dimension ntimes k times T where x[i,j,:] is the IRF of the i'th element of the state vector (vecx_t) to the j'th shock in the vector vecu_t.\nx_hat is of dimension ntimes k times T where x_hat[i,j,:] is the IRF of the agent's belief about i'th element of the state vector  (hatx_t) to the j'th shock in the vector vecu_t.\nx_hat is of dimension mtimes k times T where a[i,j,:] is the IRF of the i'th element of the action vector (veca_t) to the j'th shock in the vector vecu_t.","category":"page"},{"location":"#The-Solver-for-the-Transition-dynamics-of-Rational-Inattention-Problems-(T.R.I.P.)-1","page":"Home","title":"The Solver for the Transition dynamics of Rational Inattention Problems (T.R.I.P.)","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"The Euler equation derived in Afrouzi and Yang (2019) for the  also allows us to characterize the transition path of the information structure over time for an arbitrary initial prior. The function solve_trip(P::drip; T=100) takes the solution P=solve_drip(.) as an input and returns a trip structure that summarizes the transition path of information benefit matrics, priors and a vector for the marginal values of information over time (the input T determines the number of periods that it takes to reach to the steady state and is set to 100 by default):","category":"page"},{"location":"#","page":"Home","title":"Home","text":"struct Trip \n    P::Drip;                # problem and solution in steady state\n    T::Int;                 # length of T.R.I.P.\n    Σ_1s; Σ_ps; Ωs;         # priors, posteriors and benefit matrices \n    Ds;                     # eigenvalues of Σ_t^(0.5)Ω_tΣ_t^(0.5)\nend ","category":"page"}]
}
